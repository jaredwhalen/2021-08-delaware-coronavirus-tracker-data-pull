# download <- jump_to(sess, paste0('https://myhealthycommunity.dhss.delaware.gov', download_src))
#
#
sess <- session(gsub("/download_covid_19_data/overview", "", url))
url <- 'https://myhealthycommunity.dhss.delaware.gov/locations/county-sussex/download_covid_19_data/overview'
#
# download_src <- sess %>%
#   read_html() %>%
#   html_node(xpath = xpath) %>%
#   html_attr('href')
#
# print(download_src)
# download <- jump_to(sess, paste0('https://myhealthycommunity.dhss.delaware.gov', download_src))
#
#
sess <- session(gsub("/download_covid_19_data/overview", "", url))
x <- session_jump_to(sess, url)
data <- read_csv(x$response$content)
View(data)
links <- tibble::tribble(
~name,                                                                                              ~url,
"delaware",             "https://myhealthycommunity.dhss.delaware.gov/locations/state/download_covid_19_data/overview",
"newcastle", "https://myhealthycommunity.dhss.delaware.gov/locations/county-new-castle/download_covid_19_data/overview",
"kent",       "https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview",
"sussex",     "https://myhealthycommunity.dhss.delaware.gov/locations/county-sussex/download_covid_19_data/overview"
)
for (row in 1:nrow(links)) {
name <- links[row, 'name']
url <- links[row, 'url']
# xpath <- links[row, 'xpath']
data <- getData(url$url)
# data <- read_csv(paste('files/', url, '-', substring(Sys.time(), 1, 10), '.csv', sep=''))
list[[length(list)+1]] <- getStatistic(data, 'Cumulative Number of Positive Cases', paste(name, 'cases', sep='_'), 'people')
list[[length(list)+1]] <- getStatistic(data, 'Deaths', paste(name, 'deaths', sep='_'), 'people')
list[[length(list)+1]] <- getStatistic(data, 'Persons Tested Negative', paste(name, 'negative', sep='_'), 'people')
# list[[length(list)+1]] <- getStatistic(data, 'Total Tests', paste(name, 'tests', sep='_'), 'tests')
list[[length(list)+1]] <- getStatistic(data, 'Total Persons Tested', paste(name, 'tests', sep='_'), 'people')
# list[[length(list)+1]] <- getStatistic(data, 'Positive Tests', paste(name, 'positiveTests', sep='_'), 'tests')
# list[[length(list)+1]] <- getStatistic(data, 'New Positive Tests', paste(name, 'positiveTests', sep='_'), 'tests')
}
getData <- function(url) {
url = url
# xpath = xpath
#
# sess <- html_session(url)
#
# download_src <- sess %>%
#   read_html() %>%
#   html_node(xpath = xpath) %>%
#   html_attr('href')
#
# print(download_src)
# download <- jump_to(sess, paste0('https://myhealthycommunity.dhss.delaware.gov', download_src))
#
#
sess <- session(gsub("/download_covid_19_data/overview", "", url))
x <- session_jump_to(sess, url)
data <- read_csv(x$response$content)
return(data)
}
for (row in 1:nrow(links)) {
name <- links[row, 'name']
url <- links[row, 'url']
# xpath <- links[row, 'xpath']
data <- getData(url$url)
# data <- read_csv(paste('files/', url, '-', substring(Sys.time(), 1, 10), '.csv', sep=''))
list[[length(list)+1]] <- getStatistic(data, 'Cumulative Number of Positive Cases', paste(name, 'cases', sep='_'), 'people')
list[[length(list)+1]] <- getStatistic(data, 'Deaths', paste(name, 'deaths', sep='_'), 'people')
list[[length(list)+1]] <- getStatistic(data, 'Persons Tested Negative', paste(name, 'negative', sep='_'), 'people')
# list[[length(list)+1]] <- getStatistic(data, 'Total Tests', paste(name, 'tests', sep='_'), 'tests')
list[[length(list)+1]] <- getStatistic(data, 'Total Persons Tested', paste(name, 'tests', sep='_'), 'people')
# list[[length(list)+1]] <- getStatistic(data, 'Positive Tests', paste(name, 'positiveTests', sep='_'), 'tests')
# list[[length(list)+1]] <- getStatistic(data, 'New Positive Tests', paste(name, 'positiveTests', sep='_'), 'tests')
}
getStatistic <- function(d, q, l, u) {
d <- data %>%
mutate(date_confirmed = paste(year, month, day, sep='-')) %>%
filter(
statistic == q,
unit == u,
) %>%
select(
date_confirmed,
!!l := value
)
# if (q == "Deaths") {
#   d <- d %>%
#   group_by(date_confirmed) %>%
#   slice(1)
# }
return(d)
}
links <- tibble::tribble(
~name,                                                                                              ~url,
"delaware",             "https://myhealthycommunity.dhss.delaware.gov/locations/state/download_covid_19_data/overview",
"newcastle", "https://myhealthycommunity.dhss.delaware.gov/locations/county-new-castle/download_covid_19_data/overview",
"kent",       "https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview",
"sussex",     "https://myhealthycommunity.dhss.delaware.gov/locations/county-sussex/download_covid_19_data/overview"
)
list <- list()
for (row in 1:nrow(links)) {
name <- links[row, 'name']
url <- links[row, 'url']
# xpath <- links[row, 'xpath']
data <- getData(url$url)
# data <- read_csv(paste('files/', url, '-', substring(Sys.time(), 1, 10), '.csv', sep=''))
list[[length(list)+1]] <- getStatistic(data, 'Cumulative Number of Positive Cases', paste(name, 'cases', sep='_'), 'people')
list[[length(list)+1]] <- getStatistic(data, 'Deaths', paste(name, 'deaths', sep='_'), 'people')
list[[length(list)+1]] <- getStatistic(data, 'Persons Tested Negative', paste(name, 'negative', sep='_'), 'people')
# list[[length(list)+1]] <- getStatistic(data, 'Total Tests', paste(name, 'tests', sep='_'), 'tests')
list[[length(list)+1]] <- getStatistic(data, 'Total Persons Tested', paste(name, 'tests', sep='_'), 'people')
# list[[length(list)+1]] <- getStatistic(data, 'Positive Tests', paste(name, 'positiveTests', sep='_'), 'tests')
# list[[length(list)+1]] <- getStatistic(data, 'New Positive Tests', paste(name, 'positiveTests', sep='_'), 'tests')
}
updateCaseData = function() {
source("getCases.R")
write_csv(cases__new, paste(output_path, '/cases.csv', sep=''))
write_csv(cases__new, "./outputs/latest/cases.csv")
}
updateCaseData()
list <- list()
for (row in 1:nrow(links)) {
name <- links[row, 'name']
url <- links[row, 'url']
# xpath <- links[row, 'xpath']
data <- getData(url$url)
# data <- read_csv(paste('files/', url, '-', substring(Sys.time(), 1, 10), '.csv', sep=''))
list[[length(list)+1]] <- getStatistic(data, 'Cumulative Number of Positive Cases', paste(name, 'cases', sep='_'), 'people')
list[[length(list)+1]] <- getStatistic(data, 'Deaths', paste(name, 'deaths', sep='_'), 'people')
list[[length(list)+1]] <- getStatistic(data, 'Persons Tested Negative', paste(name, 'negative', sep='_'), 'people')
# list[[length(list)+1]] <- getStatistic(data, 'Total Tests', paste(name, 'tests', sep='_'), 'tests')
list[[length(list)+1]] <- getStatistic(data, 'Total Persons Tested', paste(name, 'tests', sep='_'), 'people')
# list[[length(list)+1]] <- getStatistic(data, 'Positive Tests', paste(name, 'positiveTests', sep='_'), 'tests')
# list[[length(list)+1]] <- getStatistic(data, 'New Positive Tests', paste(name, 'positiveTests', sep='_'), 'tests')
Sys.sleep(1000)
}
updateCaseData = function() {
source("getCases.R")
write_csv(cases__new, paste(output_path, '/cases.csv', sep=''))
write_csv(cases__new, "./outputs/latest/cases.csv")
}
updateCaseData()
library(tidyr)
library(dplyr)
library(readr)
library(httr)
library(rvest)
library(RCurl)
library(stringr)
library(jsonlite)
library(lubridate)
library(zoo)
library(stringi)
output_path = paste('./outputs/', Sys.Date(), sep='')
dir.create(output_path, showWarnings = FALSE)
updateCaseData = function() {
source("getCases.R")
write_csv(cases__new, paste(output_path, '/cases.csv', sep=''))
write_csv(cases__new, "./outputs/latest/cases.csv")
}
source("getCases.R")
setwd("~/Documents/Personal/Delaware Online/2021-08-delaware-coronavirus-tracker-data-pull")
updateCaseData = function() {
source("getCases.R")
write_csv(cases__new, paste(output_path, '/cases.csv', sep=''))
write_csv(cases__new, "./outputs/latest/cases.csv")
}
updateCaseData()
updateCaseData = function() {
source("getCases.R")
write_csv(cases__new, paste(output_path, '/cases.csv', sep=''))
write_csv(cases__new, "./outputs/latest/cases.csv")
}
updateCaseData()
updateCaseData()
source("getCases.R")
updateCaseData = function() {
source("getCases.R")
write_csv(cases__new, paste(output_path, '/cases.csv', sep=''))
write_csv(cases__new, "./outputs/latest/cases.csv")
}
updateCaseData()
updateCaseData()
links <- tibble::tribble(
~name,                                                                                              ~url,
"delaware",             "https://myhealthycommunity.dhss.delaware.gov/locations/state/download_covid_19_data/overview",
"newcastle", "https://myhealthycommunity.dhss.delaware.gov/locations/county-new-castle/download_covid_19_data/overview",
"kent",       "https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview",
"sussex",     "https://myhealthycommunity.dhss.delaware.gov/locations/county-sussex/download_covid_19_data/overview"
)
links <- tibble::tribble(
~name,                                                                                              ~url,
"delaware",             "https://myhealthycommunity.dhss.delaware.gov/locations/state/download_covid_19_data/overview",
"newcastle", "https://myhealthycommunity.dhss.delaware.gov/locations/county-new-castle/download_covid_19_data/overview",
"kent",       "https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview",
"sussex",     "https://myhealthycommunity.dhss.delaware.gov/locations/county-sussex/download_covid_19_data/overview"
)
for (link in links) (
# sess <- session()
print(gsub("/download_covid_19_data/overview", "", link$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
)
for (link in links) (
print(link)
# sess <- session()
print(gsub("/download_covid_19_data/overview", "", link$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
)
print(row)
for (row in 1:nrow(links)) {
print(row)
# sess <- session()
# print(gsub("/download_covid_19_data/overview", "", link$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
)
links <- tibble::tribble(
~name,                                                                                              ~url,
"delaware",             "https://myhealthycommunity.dhss.delaware.gov/locations/state/download_covid_19_data/overview",
"newcastle", "https://myhealthycommunity.dhss.delaware.gov/locations/county-new-castle/download_covid_19_data/overview",
"kent",       "https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview",
"sussex",     "https://myhealthycommunity.dhss.delaware.gov/locations/county-sussex/download_covid_19_data/overview"
)
for (row in 1:nrow(links)) {
print(row)
# sess <- session()
# print(gsub("/download_covid_19_data/overview", "", link$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
)
print(i)
for (i in 1:nrow(links)) {
print(i)
# sess <- session()
# print(gsub("/download_covid_19_data/overview", "", link$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
}
# sess <- session()
# print(gsub("/download_covid_19_data/overview", "", link$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
}
# for (i in 1:nrow(links)) {
for (link in links) {
print(link)
# sess <- session()
# print(gsub("/download_covid_19_data/overview", "", link$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
}
# for (i in 1:nrow(links)) {
for (link in links) {
print(link$url)
# sess <- session()
# print(gsub("/download_covid_19_data/overview", "", link$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
}
for (i in 1:nrow(links)) {
row <- links[i,]
# sess <- session()
print(gsub("/download_covid_19_data/overview", "", row$url))
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
}
for (i in 1:nrow(links)) {
row <- links[i,]
# sess <- session()
url <- gsub("/download_covid_19_data/overview", "", row$url)
# x <- session_jump_to(sess, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
#
# data <- read_csv(x$response$content)
}
sess <- session()
for (i in 1:nrow(links)) {
row <- links[i,]
# url <- gsub("/download_covid_19_data/overview", "", row$url)
# sess <- session(url)
x <- session(row$url, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
data <- read_csv(x$response$content)
print(head(data))
}
updateCaseData()
View(data)
for (i in 1:nrow(links)) {
row <- links[i,]
x <- session(row$url, 'https://myhealthycommunity.dhss.delaware.gov/locations/county-kent/download_covid_19_data/overview')
data <- read_csv(x$response$content)
print(head(data))
}
for (i in 1:nrow(links)) {
row <- links[i,]
x <- session(row$url)
data <- read_csv(x$response$content)
print(head(data))
}
updateCaseData()
updateZipCaseData = function() {
source("getZipCases.R")
write_csv(zip__new, paste(output_path, '/zips.csv', sep=''))
write_csv(zip__new, "./outputs/latest/zips.csv")
}
updateZipCaseData()
updateZipCaseData()
updateZipCaseData = function() {
source("getZipCases.R")
write_csv(zip__new, paste(output_path, '/zips.csv', sep=''))
write_csv(zip__new, "./outputs/latest/zips.csv")
}
updateZipCaseData()
updateZipCaseData = function() {
source("getZipCases.R")
write_csv(zip__new, paste(output_path, '/zips.csv', sep=''))
write_csv(zip__new, "./outputs/latest/zips.csv")
}
updateZipCaseData()
library(geckor)
?coin_history
coin_history('tether')
coin_history('tether', days ='max')
coin_history('tether', days ='max') %>%
View()
shiny::runApp('~/Documents/GitHub/tools/coingecko-chart-generator')
runApp('~/Documents/GitHub/tools/stock-data-generator')
library(curl)
curl_fetch_memory('curlhttps://finance.yahoo.com/quote/')
curl_fetch_memory('https://finance.yahoo.com/quote/')
req <- curl_fetch_memory('https://finance.yahoo.com/quote/')
parse_headers(req$headers)
req$content
rawToChar(req$content)
jsonlite::prettify(rawToChar(req$content))
jsonlite::prettify(rawToChar(req$content))
handle_cookies(req)
h <- new_handle()
handle_cookies(h)
req <- curl_fetch_memory('https://finance.yahoo.com/quote/', handle = h)
req
req <- curl_fetch_memory('https://finance.yahoo.com/quote/')
write_clip(req)
library(clipr)
write_clip(req)
write_clip(parse_headers(req$headers))
req <- curl_fetch_memory('https://finance.yahoo.com/quote/AAPL/history')
write_clip(parse_headers(req$headers))
library(httr)
GET("https://finance.yahoo.com/quote/AAPL/history")
r <- GET("https://finance.yahoo.com/quote/AAPL/history")
cookies(r)
r <- GET("uk.https://finance.yahoo.com/quote/AAPL/history")
r <- GET("https://uk.finance.yahoo.com/quote/AAPL/history")
cookies(r)
r <- GET("https://finance.yahoo.com/quote/AAPL/history")
cookies(r)
library(rvest)
r <- html('https://finance.yahoo.com/quote/AAPL/history')
library(rvest)
r <- html('https://finance.yahoo.com/quote/AAPL/history')
r <- rvest::html('https://finance.yahoo.com/quote/AAPL/history')
r <- html('https://finance.yahoo.com/quote/AAPL/history'
r <- rvest::read_html('https://finance.yahoo.com/quote/AAPL/history')
library(stringr)
r$node
r$doc
r <- read_html('https://finance.yahoo.com/quote/AAPL/history') %>%  html_text()
r
str_extract(r, pattern)
pattern <- '"CrumbStore":\{"crumb":"(?<crumb>[^"]+)"\}'
pattern <- `"CrumbStore":\{"crumb":"(?<crumb>[^"]+)"\}`
pattern <- '"CrumbStore":\\{"crumb":"(?<crumb>[^"]+)"\\}'
str_extract(r, pattern)
request_url
?session
httr::GET("https://query1.finance.yahoo.com/v7/finance/download/TSLA?period1=1620916442&period2=1652452442&interval=1d&events=history&includeAdjustedClose=true",
set_cookies(`CrumbStore` = '{\"crumb\":\"m79.Ycf7iGS\"}')
)
x <- httr::GET("https://query1.finance.yahoo.com/v7/finance/download/TSLA?period1=1620916442&period2=1652452442&interval=1d&events=history&includeAdjustedClose=true",
set_cookies(`CrumbStore` = '{\"crumb\":\"m79.Ycf7iGS\"}')
)
x$content
read_csv(x$content)
request_url <- paste0("https://query2.finance.yahoo.com/v7/finance/download/", symbol,"?period1=", to_seconds(start_date), "&period2=", to_seconds(end_date), "&interval=1d&events=history&includeAdjustedClose=true")
runApp('~/Documents/GitHub/tools/stock-data-generator')
read_html(paste0('https://finance.yahoo.com/quote/',symbol,'/history')) %>%
html_text() %>%
str_extract(pattern)
symbol <- "AAPL"
read_html(paste0('https://finance.yahoo.com/quote/',symbol,'/history')) %>%
html_text() %>%
str_extract(pattern)
cookie <- read_html(paste0('https://finance.yahoo.com/quote/',symbol,'/history')) %>%
html_text() %>%
str_extract('\\{"crumb":"(?<crumb>[^"]+)"\\}')
cookie
runApp('~/Documents/GitHub/tools/stock-data-generator')
runApp('~/Documents/GitHub/tools/stock-data-generator')
runApp('~/Documents/GitHub/tools/stock-data-generator')
url <- 'https://myhealthycommunity.dhss.delaware.gov/locations/state'
overview <- httr::GET(url,
#pass cookie
set_cookies(`policy_accepted` = "true")
) %>%
read_html() %>%
html_node("#overview")
date <- overview %>%
html_node(xpath='/html/body/div[1]/div[2]/div/main/div/div[1]/section/div/section[3]/div[1]/div/div[1]/div[1]/article/div/header/div/div/div/span[2]') %>%
html_text() %>%
as.Date(., format='%m/%d/%Y')
value <- overview %>%
html_node(xpath='/html/body/div[1]/div[2]/div/main/div/div[1]/section/div/section[2]/article[1]/div/div[2]/section[2]/div[2]/div[2]/div/div[2]/div/div/span/strong[1]') %>%
html_text()
hospitalizations__new <- data.frame(date_confirmed = date, delaware_hospitalized = as.numeric(value))
value <- overview %>%
html_node(xpath='/html/body/div[1]/div[2]/div/main/div/div[1]/section/div/section[2]/article[1]/div/div[2]/section[2]/div[2]/div[2]/div/div[2]/div/div/span/strong[1]') %>%
html_text() %>%
replace(is.na(.), 0)
zip <- 19701
print(zip)
html <- httr::GET(paste(url, zip, sep=''),
#pass cookie
set_cookies(`policy_accepted` = "true")
) %>%
read_html()
date_confirmed <- Sys.Date()
cases <- html %>%
html_node(xpath='/html/body/div[1]/div[2]/div/main/div/div[1]/section/div/section[1]/article[3]/article/div/div/div[2]/div[1]/div/div[2]/div[1]/div/div/div[1]') %>%
html_text() %>%
gsub('[^0-9.-]', '', .) %>%
as.numeric()
cases <- html %>%
html_node(xpath='/html/body/div[1]/div[2]/div/main/div/div[1]/section/div/section[1]/article[3]/article/div/div/div[2]/div[1]/div/div[2]/div[1]/div/div/div[1]') %>%
html_text()
html$doc
html %>%
html_text()
deaths <- html %>%
html_node(xpath='//*[@id="death-data"]/article/div/div/div[1]/div[1]/div/div[2]/div[1]/div/div/div[1]') %>%
html_text() %>%
gsub('[^0-9.-]', '', .) %>%
as.numeric()
cases <- html %>%
html_node(xpath='//*[@id="positive-cases-data"]/article/div/div/div[2]/div[1]/div/div[2]/div[1]/div/div/div[1]') %>%
html_text() %>%
gsub('[^0-9.-]', '', .) %>%
as.numeric()
cases <- html %>%
html_node(xpath='/html/body/div[1]/div[2]/div/main/div/div[1]/section/div/section[1]/article[3]/article/div/div/div[2]/div[1]/div/div[2]/div[1]/div/div') %>%
html_text()
cases <- html %>%
html_node(xpath='/html/body/div[1]/div[2]/div/main/div/div[1]/section/div/section[1]/article[3]/article/div/div/div[2]/div[2]/div/div/div[1]/div[2]/div') %>%
html_text() %>%
gsub('[^0-9.-]', '', .) %>%
as.numeric()
html %>%
html_node('.c-dash-slat__value.c-dash-slat__value--primary')
html %>%
html_node('.c-dash-slat__value.c-dash-slat__value--primary') %>%
html_text()
html <- httr::GET(paste(url, zip, sep=''),
#pass cookie
set_cookies(`policy_accepted` = "true")
) %>%
read_html()
date_confirmed <- Sys.Date()
html %>%
html_node('.c-dash-slat__value.c-dash-slat__value--primary') %>%
html_text()
url <- 'https://myhealthycommunity.dhss.delaware.gov/locations/zip-code-'
date_time<-Sys.time()
while((as.numeric(Sys.time()) - as.numeric(date_time))<1){} #dummy while loop
print(zip)
html <- httr::GET(paste(url, zip, sep=''),
#pass cookie
set_cookies(`policy_accepted` = "true")
) %>%
read_html()
date_confirmed <- Sys.Date()
cases <- html %>%
html_node(xpath='/html/body/div[1]/div[2]/div/main/div/div[1]/section/div/section[1]/article[3]/article/div/div/div[2]/div[1]/div/div[2]/div[1]/div/div/div[1]') %>%
html_text() %>%
gsub('[^0-9.-]', '', .) %>%
as.numeric()
html %>%
html_node('.c-dash-slat__value.c-dash-slat__value--primary') %>%
html_text()
updateZipCaseData = function() {
source("getZipCases.R")
write_csv(zip__new, paste(output_path, '/zips.csv', sep=''))
write_csv(zip__new, "./outputs/latest/zips.csv")
}
message(cases, deaths)
message(cases, " ",deaths)
message("Cases:", cases, " Deaths: ",deaths)
updateZipCaseData = function() {
source("getZipCases.R")
write_csv(zip__new, paste(output_path, '/zips.csv', sep=''))
write_csv(zip__new, "./outputs/latest/zips.csv")
}
updateZipCaseData()
runApp('~/Documents/GitHub/tools/coingecko-chart-generator')
